{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO LIST\n",
    "\n",
    "- [x] Choose Amsterdam / Rotterdam via parameter\n",
    "- [x] Add Lags for remaining districts\n",
    "- [x] Replace `lagged` variables with `diff`\n",
    "- [x] Look-ahead values (e.g. 1 min 5 min 10 min 30 min)\n",
    "  - [x] Prediction function should be tunable\n",
    "- [x] Confusion Matrix per bin - find out model inaccuracies\n",
    "- [x] Add `LightGBM` model\n",
    "- [ ] Create Benchmarks\n",
    "  - [x] Test accuracy (classification report)\n",
    "  - [ ] train-time (...)\n",
    "  - [ ] inference-time (...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    balanced_accuracy_score,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    TimeSeriesSplit,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "import geopandas as gpd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# from skopt import BayesSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/final/points_per_district_full.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>district_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Bedrijvenpark Noord-West</th>\n",
       "      <th>Bedrijventerrein Schieveen</th>\n",
       "      <th>Botlek</th>\n",
       "      <th>Charlois</th>\n",
       "      <th>Delfshaven</th>\n",
       "      <th>Feijenoord</th>\n",
       "      <th>Hillegersberg-Schiebroek</th>\n",
       "      <th>Hoek van Holland</th>\n",
       "      <th>Hoogvliet</th>\n",
       "      <th>...</th>\n",
       "      <th>Noord</th>\n",
       "      <th>Overschie</th>\n",
       "      <th>Pernis</th>\n",
       "      <th>Prins Alexander</th>\n",
       "      <th>Rivium</th>\n",
       "      <th>Rotterdam Centrum</th>\n",
       "      <th>Spaanse Polder</th>\n",
       "      <th>Vondelingenplaat</th>\n",
       "      <th>Waalhaven</th>\n",
       "      <th>Ĳsselmonde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-18 06:21:58</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>327</td>\n",
       "      <td>520</td>\n",
       "      <td>496</td>\n",
       "      <td>513</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>391</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>732</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-18 06:23:00</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>328</td>\n",
       "      <td>520</td>\n",
       "      <td>497</td>\n",
       "      <td>512</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>390</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-18 06:24:02</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>329</td>\n",
       "      <td>519</td>\n",
       "      <td>498</td>\n",
       "      <td>512</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>391</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>732</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-18 06:25:04</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>329</td>\n",
       "      <td>519</td>\n",
       "      <td>499</td>\n",
       "      <td>512</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>391</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>734</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-18 06:26:07</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>329</td>\n",
       "      <td>517</td>\n",
       "      <td>499</td>\n",
       "      <td>515</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>391</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>733</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "district_id           timestamp  Bedrijvenpark Noord-West  \\\n",
       "0           2024-06-18 06:21:58                        18   \n",
       "1           2024-06-18 06:23:00                        18   \n",
       "2           2024-06-18 06:24:02                        18   \n",
       "3           2024-06-18 06:25:04                        18   \n",
       "4           2024-06-18 06:26:07                        18   \n",
       "\n",
       "district_id  Bedrijventerrein Schieveen  Botlek  Charlois  Delfshaven  \\\n",
       "0                                     8       1       327         520   \n",
       "1                                     8       1       328         520   \n",
       "2                                     8       1       329         519   \n",
       "3                                     8       1       329         519   \n",
       "4                                     8       1       329         517   \n",
       "\n",
       "district_id  Feijenoord  Hillegersberg-Schiebroek  Hoek van Holland  \\\n",
       "0                   496                       513                15   \n",
       "1                   497                       512                15   \n",
       "2                   498                       512                15   \n",
       "3                   499                       512                15   \n",
       "4                   499                       515                15   \n",
       "\n",
       "district_id  Hoogvliet  ...  Noord  Overschie  Pernis  Prins Alexander  \\\n",
       "0                    4  ...    391         37       1              238   \n",
       "1                    4  ...    390         37       1              238   \n",
       "2                    4  ...    391         37       1              238   \n",
       "3                    4  ...    391         37       1              238   \n",
       "4                    4  ...    391         37       1              238   \n",
       "\n",
       "district_id  Rivium  Rotterdam Centrum  Spaanse Polder  Vondelingenplaat  \\\n",
       "0                 1                732              46                 1   \n",
       "1                 1                730              46                 1   \n",
       "2                 1                732              46                 1   \n",
       "3                 1                734              46                 1   \n",
       "4                 1                733              46                 1   \n",
       "\n",
       "district_id  Waalhaven  Ĳsselmonde  \n",
       "0                   10         225  \n",
       "1                   10         225  \n",
       "2                   10         225  \n",
       "3                   10         225  \n",
       "4                   10         225  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    df.pivot_table(\n",
    "        index=\"timestamp\", columns=\"district_id\", values=\"crowd\", aggfunc=\"sum\"\n",
    "    )\n",
    "    .ffill()\n",
    "    .bfill()\n",
    "    .astype(np.uint16)\n",
    "    .sort_values(by=\"timestamp\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Start Date: {pd.to_datetime(df['timestamp'].min(), unit='s')}\\nEnd Date:   {pd.to_datetime(df['timestamp'].max(), unit='s')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "1. Binning\n",
    "2. Feature Extraction\n",
    "   1. Time-related Features\n",
    "      1. Hour\n",
    "      2. Minute\n",
    "      3. Day of week\n",
    "   2. Lagged Features\n",
    "      1. 1-10 Minutes\n",
    "      2. 15 Minutes\n",
    "      3. 30 Minutes\n",
    "      4. 60 Minutes\n",
    "   3. Rolling Mean Features\n",
    "      1. Mean\n",
    "      2. Std\n",
    "      3. Var\n",
    "      4. Kurtosis\n",
    "      5. Skewness\n",
    "   4. Exponential Smoothing Features\n",
    "      1. 5 Minutes\n",
    "      2. 10 Minutes\n",
    "      3. 15 Minutes\n",
    "      4. 30 Minutes\n",
    "      5. 60 Minutes\n",
    "3. Cyclic Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crowd_levels(df, target_district):\n",
    "    target_column = f'{target_district.replace(\" \", \"_\")}_c_lvl'\n",
    "\n",
    "    mean_crowd = df[target_district].mean()\n",
    "    std_crowd = df[target_district].std()\n",
    "\n",
    "    # Define bins based on mean and standard deviation\n",
    "    # bins = [\n",
    "    #     float(\"-inf\"),\n",
    "    #     mean_crowd - 1.0 * (std_crowd if std_crowd != 0 else 1),\n",
    "    #     mean_crowd - 0.35 * (std_crowd if std_crowd != 0 else 1),\n",
    "    #     mean_crowd + 0.35 * (std_crowd if std_crowd != 0 else 1),\n",
    "    #     mean_crowd + 1.0 * (std_crowd if std_crowd != 0 else 1),\n",
    "    #     float(\"inf\"),\n",
    "    # ]\n",
    "\n",
    "    bins = [\n",
    "        float(\"-inf\"),\n",
    "        mean_crowd - 0.55 * (std_crowd if std_crowd != 0 else 1),\n",
    "        mean_crowd + 0.55 * (std_crowd if std_crowd != 0 else 1),\n",
    "        float(\"inf\"),\n",
    "    ]\n",
    "    out = pd.cut(\n",
    "        df[target_district],\n",
    "        bins=bins,\n",
    "        labels=list(range(len(bins) - 1)),\n",
    "        include_lowest=True,\n",
    "    ).astype(np.uint8)\n",
    "\n",
    "    return out, target_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-related features\n",
    "time_related_features = {\n",
    "    \"hour\": df[\"timestamp\"].dt.hour.astype(np.uint8),\n",
    "    \"day_of_week\": df[\"timestamp\"].dt.day_of_week.astype(np.uint8),\n",
    "    \"minute\": df[\"timestamp\"].dt.minute.astype(np.uint8),\n",
    "    \"is_weekend\": (df[\"timestamp\"].dt.weekday >= 5).astype(np.uint8),\n",
    "}\n",
    "\n",
    "lagged_features = {}\n",
    "rolling_features = {}\n",
    "exp_smoothing_features = {}\n",
    "# windows = [5, 10, 15, 30] + [60 * i for i in range(1, 7)] + [60 * 24]\n",
    "windows = [5, 10, 15, 30]\n",
    "\n",
    "for district in df.columns[1:]:\n",
    "    lagged_features.update(\n",
    "        {\n",
    "            f\"{district.replace(' ', '_')}_lag_{i}\": df[district].shift(i).diff()\n",
    "            for i in list(range(1, 11)) + [15, 30, 60]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    rolling_features.update(\n",
    "        {\n",
    "            f\"{district.replace(' ', '_')}_rolling_{stat}_{window}\": getattr(\n",
    "                df[district].rolling(window=window), stat\n",
    "            )()\n",
    "            for window in windows\n",
    "            for stat in [\"mean\", \"std\", \"var\", \"skew\", \"kurt\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    exp_smoothing_features.update(\n",
    "        {\n",
    "            f\"{district.replace(' ', '_')}_ema_{window}\": df[district]\n",
    "            .ewm(span=window, adjust=True)\n",
    "            .mean()\n",
    "            for window in windows\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_df = pd.concat(\n",
    "    [\n",
    "        # After Feature Extraction we can drop the original target column\n",
    "        df,\n",
    "        pd.DataFrame(lagged_features),\n",
    "        pd.DataFrame(rolling_features),\n",
    "        pd.DataFrame(exp_smoothing_features),\n",
    "        pd.DataFrame(time_related_features),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_boundaries = gpd.read_file(\"../misc/rotterdam_.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_boundaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = {}\n",
    "for target_district in df.columns[1:]:\n",
    "    labels, target_column = create_crowd_levels(df, target_district)\n",
    "    target_columns[target_column] = labels\n",
    "\n",
    "target_labels = [k for k in target_columns.keys()]\n",
    "lagged_df[target_labels] = pd.DataFrame(target_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 5\n",
    "temp = lagged_df.copy(deep=True)\n",
    "\n",
    "shifted_targets = temp[target_labels].shift(-step)\n",
    "temp[target_labels] = shifted_targets\n",
    "\n",
    "temp = temp.dropna().reset_index(drop=True)\n",
    "\n",
    "temp[target_labels] = temp[target_labels].astype(np.uint8)\n",
    "temp.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "y_labels = temp.columns[-len(target_labels) :]\n",
    "X, y = temp.drop(columns=y_labels), temp[y_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"TRAIN: {X_train.shape}, {y_train.shape}, \\nTEST: {X_test.shape}, {y_test.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.select_dtypes(include=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier(\n",
    "    boosting_type=\"gbdt\",\n",
    "    objective=[\"multiclass\"],\n",
    "    force_col_wise=True,\n",
    "    num_class=3,\n",
    "    num_leaves=3,\n",
    "    max_depth=10,\n",
    "    reg_lambda=0.7,\n",
    "    colsample_bytree=0.5,\n",
    "    learning_rate=0.01,\n",
    "    reg_alpha=0.3,\n",
    "    subsample=0.5,\n",
    "    n_jobs=-1,\n",
    "    verbosity=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# pipeline = build_pipe(xgb)\n",
    "pipeline = build_pipe(lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_cv = TimeSeriesSplit(n_splits=5)\n",
    "scoring = {\n",
    "    \"accuracy\": make_scorer(balanced_accuracy_score),\n",
    "    \"f1_micro\": make_scorer(f1_score, average=\"micro\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_cv = TimeSeriesSplit(n_splits=5)\n",
    "scoring = {\n",
    "    \"accuracy\": make_scorer(balanced_accuracy_score),\n",
    "    \"f1_micro\": make_scorer(f1_score, average=\"micro\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tuned:\n",
    "    param_grid = {\n",
    "        # \"classifier__n_estimators\": np.arange(50, 300, 50),\n",
    "        # \"classifier__max_depth\": np.arange(3, 10, 2),\n",
    "        \"classifier__estimator__learning_rate\": [0.01, 0.1, 0.3],\n",
    "        \"classifier__estimator__subsample\": [0.5, 0.7, 1.0],\n",
    "        # \"classifier__estimator__colsample_bytree\": [0.5, 0.8, 1.0],\n",
    "        # \"classifier__estimator__reg_alpha\": np.linspace(0.3, 1.0, 3).round(1),\n",
    "        # \"classifier__reg_lambda\": np.linspace(0.3, 1.0, 3).round(1)\n",
    "    }\n",
    "    print(f\"====== Performing Grid Search ======\\n\")\n",
    "\n",
    "    param_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=ts_cv,\n",
    "        scoring=scoring,\n",
    "        refit=\"f1_micro\",\n",
    "        n_jobs=1,\n",
    "        verbose=1,\n",
    "        error_score=\"raise\",\n",
    "    )\n",
    "    param_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n====== Grid Search Results ======\")\n",
    "    print(f\"Best score: {param_search.best_score_:.3f}\")\n",
    "    print(f\"Best parameters:\")\n",
    "    for key, value in param_search.best_params_.items():\n",
    "        print(f\"    - {key.split('__')[-1]}: {value}\")\n",
    "\n",
    "    print(\n",
    "        \"\".join(\n",
    "            f\"{key.replace('_', ' ').title()}: {value.mean():.3f} ± {value.std():.3f}\"\n",
    "            for key, value in param_search.cv_results_.items()\n",
    "            if key.startswith((\"mean_test\", \"test\"))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    best_model = param_search.best_estimator_\n",
    "    best_model.fit(X_train, y_train)\n",
    "else:\n",
    "    print(\"Model is pre-tuned\")\n",
    "    model_path = f\"models/{pipeline[1].__class__.__name__}_{step}.pkl\"\n",
    "    with open(model_path, \"rb\") as model:\n",
    "        print(\"Loading Model...\")\n",
    "        best_model = pickle.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bayesian Optimization\n",
    "# bayes_space = {}\n",
    "\n",
    "# bayes_search = BayesSearchCV(\n",
    "#     pipeline,\n",
    "#     search_spaces=bayes_space,\n",
    "#     scoring=\"f1_micro\",\n",
    "#     cv=ts_cv,\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1,\n",
    "#     random_state=42,\n",
    "# )\n",
    "\n",
    "# bayes_search.fit(X_train, y_train)\n",
    "# print(f\"Best Params from Bayesian Optimization: {bayes_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = cross_validate(\n",
    "    best_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=ts_cv,\n",
    "    scoring=scoring,\n",
    "    error_score=\"raise\",\n",
    ")\n",
    "\n",
    "print(\"\\n====== Train Set ======\")\n",
    "for key, value in cv_result.items():\n",
    "    (\n",
    "        print(\n",
    "            f\"CV-{key.replace('_', ' ').title()}: {value.mean():.3f} ± {value.std():.3f}\"\n",
    "        )\n",
    "        if key.startswith((\"mean_test\", \"test\"))\n",
    "        else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_test = cross_validate(\n",
    "    best_model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    cv=ts_cv,\n",
    "    scoring=scoring,\n",
    "    error_score=\"raise\",\n",
    ")\n",
    "print(\"\\n====== Test Set ======\")\n",
    "for key, value in cv_results_test.items():\n",
    "    (\n",
    "        print(\n",
    "            f\"CV-{key.replace('_', ' ').title()}: {value.mean():.3f} ± {value.std():.3f}\"\n",
    "        )\n",
    "        if key.startswith((\"mean_test\", \"test\"))\n",
    "        else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = (\n",
    "    pd.DataFrame(data=[X_train.columns, best_model[1].feature_importances_])\n",
    "    .T.rename(\n",
    "        {\n",
    "            0: \"feature\",\n",
    "            1: \"importance\",\n",
    "        },\n",
    "        axis=1,\n",
    "    )\n",
    "    .sort_values(by=\"importance\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.tail(10).plot.barh(x=\"feature\", y=\"importance\", figsize=(8, 6))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.legend().set_visible(False)\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.gca().spines[[\"right\", \"bottom\", \"top\"]].set_visible(False)\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "_ = ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        digits=3,\n",
    "        target_names=[\"low\", \"medium\", \"high\"],\n",
    "    )\n",
    ")\n",
    "print(\"============================================\")\n",
    "print(f\"Balanced Accuracy Score: {balanced_accuracy_score(y_test, y_pred):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation of the Testing Set:\n",
    "\n",
    "- XGBClassifier\n",
    "  - 5 minutes\n",
    "    - Accuracy: 0.944 ± 0.020\n",
    "    - F1 Micro: 0.944 ± 0.020\n",
    "  - 10 minutes\n",
    "    - Accuracy: 0.867 ± 0.097\n",
    "    - F1 Micro: 0.867 ± 0.097\n",
    "  - 30 minutes\n",
    "    - Accuracy: 0.829 ± 0.119\n",
    "    - F1 Micro: 0.829 ± 0.119\n",
    "  - 60 minutes\n",
    "    - Accuracy: 0.644 ± 0.212\n",
    "    - F1 Micro: 0.644 ± 0.212\n",
    "- LGBMClassifier\n",
    "  - 5 minutes\n",
    "    - Accuracy: 0.770 ± 0.141\n",
    "    - F1 Micro: 0.916 ± 0.106\n",
    "    - Balanced Accuracy Score: 95.91%\n",
    "  - 10 minutes\n",
    "    - Accuracy:\n",
    "    - F1 Micro:\n",
    "  - 30 minutes\n",
    "    - Accuracy:\n",
    "    - F1 Micro:\n",
    "  - 60 minutes\n",
    "    - Accuracy: 0.664 ± 0.134\n",
    "    - F1 Micro: 0.750 ± 0.153\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-bvit9Y5v-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
